{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['items', '/datalake/silver/stagging/17062024_173700', '/datalake/silver/stagging/17062024_173918', '/datalake/silver/stagging/17062024_173943', '/datalake/silver/stagging/17062024_174021', '/datalake/silver/stagging/17062024_174129', '/datalake/silver/stagging/17062024_174759', '/datalake/silver/stagging/17062024_175022', '/datalake/silver/stagging/17062024_175116', '']\n",
      "['/datalake/silver/stagging/17062024_173700', '/datalake/silver/stagging/17062024_173918', '/datalake/silver/stagging/17062024_173943', '/datalake/silver/stagging/17062024_174021', '/datalake/silver/stagging/17062024_174129', '/datalake/silver/stagging/17062024_174759', '/datalake/silver/stagging/17062024_175022', '/datalake/silver/stagging/17062024_175116']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------------------+-----------+-----------+-----------------+--------------------+\n",
      "|latitude| longitude|               date|customer_id|employee_id|quantity_products|            order_id|\n",
      "+--------+----------+-------------------+-----------+-----------+-----------------+--------------------+\n",
      "|6.181855|-75.563697|17/06/2024 17:03:30|       6531|       null|               50|fdafbb34-2704-4c3...|\n",
      "|6.232705|-75.528248|17/06/2024 17:03:42|       5669|       null|               36|3c9b6fb3-55d2-40f...|\n",
      "|6.283395| -75.54913|17/06/2024 17:03:54|       1097|       null|               43|596bd63c-67d6-48e...|\n",
      "|6.250412|-75.593722|17/06/2024 17:03:31|       5710|       null|               24|cd169ef0-1ec8-46e...|\n",
      "|6.223835|-75.598557|17/06/2024 17:03:43|       6373|       null|               36|d849d279-1426-4af...|\n",
      "+--------+----------+-------------------+-----------+-----------+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1324"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"DataProcessing\").getOrCreate()\n",
    "\n",
    "command = \"hadoop fs -ls /datalake/silver/stagging | awk '{print $NF}'\"\n",
    "dir_names = subprocess.check_output(command, shell=True).decode().split('\\n')\n",
    "print(dir_names)\n",
    "array_silver =[]\n",
    "for dir_name in dir_names:\n",
    "    if (dir_name != \"items\" and dir_name != \"\") :\n",
    "        array_silver.append(dir_name)\n",
    "        command = f\"hadoop fs -ls {dir_name}\" + \"| awk '{print $NF}'\"\n",
    "        file_names = subprocess.check_output(command, shell=True).decode().split('\\n')\n",
    "        for name in file_names:\n",
    "            if \".parquet\" in name:\n",
    "                #print(name)\n",
    "                pass\n",
    "                \n",
    "print(array_silver)\n",
    "df = spark.read.parquet(*array_silver)\n",
    "df.show(5)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
